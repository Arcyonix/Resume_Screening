{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hiring a Perfect Machine Learning Engineer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing of necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\jefft\\anaconda3\\envs\\aiiproject\\lib\\site-packages (21.2.2)\n",
      "Collecting pip\n",
      "  Downloading pip-21.3.1-py3-none-any.whl (1.7 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 21.2.2\n",
      "    Uninstalling pip-21.2.2:\n",
      "      Successfully uninstalled pip-21.2.2\n",
      "Successfully installed pip-21.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "\n",
    "!pip install PyMuPDF\n",
    "\n",
    "!pip install XGBoost\n",
    "\n",
    "!pip install tensorflow\n",
    "\n",
    "!pip install transformers\n",
    "!pip install tf-keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import fitz  # PyMuPDF\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import xgboost as XGB\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "import tensorflow as tf\n",
    "\n",
    "from transformers import DistilBertTokenizer, TFDistilBertModel\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the Data\n",
    "Preprocessing the Data (Job Descriptions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function to extract information for job description based on their headers\n",
    "def extract_text_between_phrases(pdf_path, start_phrase, end_phrase):\n",
    "    text = ''\n",
    "    doc = fitz.open(pdf_path)\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc.load_page(page_num)\n",
    "        page_text = page.get_text()\n",
    "        start_index = page_text.find(start_phrase)\n",
    "        if start_index != -1:\n",
    "            end_index = page_text.find(end_phrase, start_index + len(start_phrase))\n",
    "            if end_index != -1:\n",
    "                text += page_text[start_index + len(start_phrase):end_index]\n",
    "                break\n",
    "            else:\n",
    "                text += page_text[start_index + len(start_phrase):]\n",
    "        elif text: \n",
    "            end_index = page_text.find(end_phrase)\n",
    "            if end_index != -1:\n",
    "                text += page_text[:end_index]\n",
    "                break\n",
    "            else:\n",
    "                text += page_text\n",
    "    doc.close()\n",
    "    return text.strip()\n",
    "pdf_path = \"Dataset\\Job description.pdf\"\n",
    "## this is a case where we set the fix format for the job description pdf which can be done easily for the HR side. With this, the code can run for any type of job the hr finds , not just for this specific example.\n",
    "\n",
    "## extract what you will do\n",
    "start_phrase = \"What youâ€™ll do\"\n",
    "end_phrase = \"Experience and qualifications\"\n",
    "Job_Scope = extract_text_between_phrases(pdf_path, start_phrase, end_phrase)\n",
    "#print(Job_Scope)\n",
    "## extract experience and qualifcations\n",
    "start_phrase = \"Experience and qualifications\"\n",
    "end_phrase = \"Technical expertise\"\n",
    "Experience_and_qualifications = extract_text_between_phrases(pdf_path, start_phrase, end_phrase)\n",
    "#print(Experience_and_qualifications)\n",
    "\n",
    "## technical expertise\n",
    "    #must have\n",
    "start_phrase = \"Must have\"\n",
    "end_phrase = \"Considered as a plus\"\n",
    "Technical_expertise = extract_text_between_phrases(pdf_path, start_phrase, end_phrase)\n",
    "#print(Technical_expertise)\n",
    "    #considered as a plus\n",
    "start_phrase = \"Considered as a plus\"\n",
    "end_phrase = \"Your job type\"\n",
    "plus_points = extract_text_between_phrases(pdf_path, start_phrase, end_phrase)\n",
    "#print(plus_points)\n",
    "\n",
    "combined_information = Technical_expertise.strip() + \"\\n\" + plus_points.strip()\n",
    "# preprocess the combined information\n",
    "print(combined_information)\n",
    "#not have used this portion but it is good for references for future works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraction of the text in the resume given fitz from pyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('Dataset/train.csv')\n",
    "test = pd.read_csv('Dataset/test.csv')\n",
    "\n",
    "#path for the dataset, etc the resumes pdfs\n",
    "train_path = \"Dataset/trainResumes/\"\n",
    "test_path = \"Dataset/testResumes/\"\n",
    "\n",
    "# initialise an empty list for the texts extracted from the resume pdf\n",
    "train_resumes = []\n",
    "test_resumes = []\n",
    "\n",
    "# ids\n",
    "train_ids = list(train.CandidateID)\n",
    "test_ids = list(test.CandidateID)\n",
    "\n",
    "#function to get the text extraction from the pdf file\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    with fitz.open(pdf_path) as doc:\n",
    "        for page in doc:\n",
    "            text += page.get_text()\n",
    "    return text\n",
    "\n",
    "#function to extract multiple pdfs at once and store into our list\n",
    "def pdf_to_string(path,ids,resumes):\n",
    "     for i in ids:\n",
    "        main_path = path+i+'.pdf'\n",
    "        text = extract_text_from_pdf(main_path)\n",
    "        str_list = text.split()\n",
    "        str_list = str_list[:]\n",
    "        string = ' '.join(str_list)\n",
    "        resumes.append(string)\n",
    "\n",
    "\n",
    "pdf_to_string(train_path, train_ids, train_resumes)\n",
    "pdf_to_string(test_path,  test_ids, test_resumes)\n",
    "\n",
    "# test\n",
    "print(train_resumes[0])\n",
    "print(test_resumes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now properly preprocessing of the text\n",
    "\n",
    "# lowercasing all letters\n",
    "train_resumes_lower = []\n",
    "for resume in train_resumes:\n",
    "    train_resumes_lower.append(resume.lower())\n",
    "\n",
    "test_resumes_lower = []\n",
    "for resume in test_resumes:\n",
    "    test_resumes_lower.append(resume.lower())\n",
    "\n",
    "## test to select words that are more impactful based on job description\n",
    "combined_information.lower()\n",
    "combined_information.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "key_word = [word for word in combined_information.split() if len(word) >= 1]\n",
    "print(key_word)\n",
    "## not used in the end\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "\n",
    "# punctuation removal\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "train_punc_removed = []\n",
    "for resume in train_resumes_lower:\n",
    "    punc_removed = remove_punctuation(resume)\n",
    "    train_punc_removed.append(punc_removed)\n",
    "\n",
    "test_punc_removed = []\n",
    "for resume in test_resumes_lower:\n",
    "    punc_removed = remove_punctuation(resume)\n",
    "    test_punc_removed.append(punc_removed)\n",
    "#----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# stopwords removal and remove single words\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "print(STOPWORDS)\n",
    "def remove_stopwords(text):\n",
    "    return \" \".join([word for word in str(text).split() if len(word) > 1 and word not in STOPWORDS])\n",
    "\n",
    "train_stopwords_removed = []\n",
    "for resume in train_punc_removed:\n",
    "    stopwords_removed = remove_stopwords(resume)\n",
    "    train_stopwords_removed.append(stopwords_removed)\n",
    "\n",
    "test_stopwords_removed = []\n",
    "for resume in test_punc_removed:\n",
    "    stopwords_removed = remove_stopwords(resume)\n",
    "    test_stopwords_removed.append(stopwords_removed)\n",
    "#----------------------------------------------------------------------------------------\n",
    "\n",
    "# lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "wordnet_map = {\"N\":wordnet.NOUN, \"V\":wordnet.VERB, \"J\":wordnet.ADJ, \"R\":wordnet.ADV}\n",
    "def lemmatize_words(text):\n",
    "    pos_tagged_text = nltk.pos_tag(text.split())\n",
    "    return \" \".join([lemmatizer.lemmatize(word, wordnet_map.get(pos[0], wordnet.NOUN)) for word, pos in pos_tagged_text])\n",
    "\n",
    "train_lemma = []\n",
    "for resume in train_stopwords_removed:\n",
    "    lemma = lemmatize_words(resume)\n",
    "    train_lemma.append(lemma)\n",
    "\n",
    "test_lemma = []\n",
    "for resume in test_stopwords_removed:\n",
    "    lemma = lemmatize_words(resume)\n",
    "    test_lemma.append(lemma)\n",
    "#----------------------------------------------------------------------------------------\n",
    "# to check if each of the preprocessing works\n",
    "print(\"train_punc_removed:\\n\",train_punc_removed[0])\n",
    "print(\"test_punc_removed:\\n\",test_punc_removed[0])\n",
    "print(\"train_stopwords_removed:\\n\",train_stopwords_removed[0])\n",
    "print(\"test_stopwords_removed:\\n\",test_stopwords_removed[0])\n",
    "print(\"train_lemma\\n\",train_lemma[0])\n",
    "print(\"test_lemma\\n\",test_lemma[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# datasets\n",
    "train = pd.read_csv('dataset/train.csv')\n",
    "test = pd.read_csv('dataset/test(with_results).csv')\n",
    "\n",
    "# preprocessed and final dataset dataset\n",
    "train_df = pd.concat([train, pd.DataFrame(train_lemma, columns=['resumes'])], axis = 1)\n",
    "test_df = pd.concat([test, pd.DataFrame(test_lemma, columns=['resumes'])], axis = 1)\n",
    "\n",
    "print(train_df.head())\n",
    "print(test_df.head())\n",
    "\n",
    "# apply TFIDF\n",
    "tfidf = TfidfVectorizer(max_features=10000, \n",
    "                        strip_accents='unicode', \n",
    "                        analyzer='word', #this is where tokenization is done\n",
    "                        lowercase=False,\n",
    "                        ngram_range=(1, 1), \n",
    "                        stop_words = 'english')\n",
    "\n",
    "tfidf_matrix_train = tfidf.fit_transform(train_df['resumes'])\n",
    "tfidf_matrix_test = tfidf.transform(test_df['resumes'])\n",
    "print(tfidf_matrix_train.shape)\n",
    "print(tfidf_matrix_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling and Score analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# dependent features (y values)\n",
    "y_train = train_df['Match Percentage']\n",
    "y_test = test_df['Match Percentage']\n",
    "\n",
    "# define the multiple machine learning models\n",
    "models = {\n",
    "    \"XGBoost\": XGB.XGBRegressor(learning_rate=0.005, \n",
    "                             n_estimators=700, \n",
    "                             objective='reg:squarederror', \n",
    "                             max_depth=8, \n",
    "                             reg_lambda=1.3,\n",
    "                             gamma=1,\n",
    "                             min_child_weight=1.5,\n",
    "                             max_delta_step=100,\n",
    "                             random_state=31),\n",
    "    \"SVM\": SVR(kernel='linear'),  \n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"KNN\": KNeighborsRegressor(n_neighbors=5),\n",
    "    \"LinearRegression\" : LinearRegression(),\n",
    "    \"DecisionTreeRegressor\" :DecisionTreeRegressor(max_depth=50) \n",
    "    #add more models if needed\n",
    "\n",
    "}\n",
    "# print the header for the table\n",
    "print(\"| {:<25} | {:<10} |{:<5} | {:<5} | {:<5} |\".format(\"Model\", \"Score\", \"Mean Absolute Error\" ,\"Mean Square Error\" , \"r2 score\"))\n",
    "print(\"+--------------------------+-------------++-------------++-------------++-------------+\")\n",
    "\n",
    "# train and make predictions for each model\n",
    "for model_name, model in models.items():\n",
    "    model.fit(tfidf_matrix_train, y_train)\n",
    "    preds = model.predict(tfidf_matrix_test)\n",
    "    mse = mean_squared_log_error(y_test, preds)\n",
    "    mae = mean_absolute_error(y_test, preds)  \n",
    "    mse_regression = mean_squared_error(y_test, preds)  \n",
    "    r2 = r2_score(y_test, preds)  \n",
    "    score = 100 * max(0, 1 - mse)\n",
    "    print(f\"| {model_name:25} | {score:10.2f} | {mae:10.2f} | {mse_regression:10.2f} | {r2:10.2f} |\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Was testing to pick out best features but end up didnt train as well.\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "X_train = tfidf_matrix_train\n",
    "X_test = tfidf_matrix_test\n",
    "\n",
    "# Initialize an empty set to store selected features\n",
    "selected_features = []\n",
    "\n",
    "# Initialize a list to store the performance of each feature subset\n",
    "best_scores = []\n",
    "\n",
    "# Initialize a base model (e.g., Linear Regression)\n",
    "model = LinearRegression()\n",
    "\n",
    "# Number of features to select\n",
    "num_features = X_train.shape[1]\n",
    "\n",
    "for i in range(num_features):\n",
    "    # Initialize variables to keep track of the best feature and its score\n",
    "    best_feature = None\n",
    "    best_score = float('inf')  # For regression, lower is better\n",
    "    \n",
    "    # Iterate over remaining features\n",
    "    for feature_idx in range(X_train.shape[1]):\n",
    "        # Check if the feature is not already selected\n",
    "        if feature_idx not in selected_features:\n",
    "            # Add the feature index to the selected features\n",
    "            selected_features.append(feature_idx)\n",
    "            \n",
    "            # Train the model using selected features\n",
    "            model.fit(X_train[:, selected_features], y_train)\n",
    "            \n",
    "            # Make predictions on the test set\n",
    "            y_pred = model.predict(X_test[:, selected_features])\n",
    "            \n",
    "            # Calculate evaluation metric (e.g., Mean Squared Error)\n",
    "            score = mean_squared_error(y_test, y_pred)\n",
    "            \n",
    "            # Check if the current feature subset improves performance\n",
    "            if score < best_score:\n",
    "                best_score = score\n",
    "                best_feature = feature_idx\n",
    "            \n",
    "            # Remove the feature index from the selected features (backtrack)\n",
    "            selected_features.remove(feature_idx)\n",
    "    \n",
    "    # Add the best feature index to the selected features\n",
    "    selected_features.append(best_feature)\n",
    "    \n",
    "    # Add the performance of the best feature subset to the list\n",
    "    best_scores.append(best_score)\n",
    "    \n",
    "\n",
    "# Select the feature subset with the best performance\n",
    "best_feature_subset = selected_features[:best_scores.index(min(best_scores))+1]\n",
    "print(\"Best feature subset indices:\", best_feature_subset)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\"\n",
    "# Train the model using the selected features\n",
    "model.fit(X_train[:, best_feature_subset], y_train)\n",
    "preds = model.predict(tfidf_matrix_test)\n",
    "mse = mean_squared_log_error(y_test, preds)\n",
    "core = 100 * max(0, 1 - mse)\n",
    "\"\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to plot some scatterplot to see\n",
    "colors = ['blue', 'green', 'red', 'cyan', 'magenta', 'black']\n",
    "i = 0\n",
    "for model_name, model in models.items():\n",
    "    model.fit(tfidf_matrix_train, y_train)\n",
    "    preds = model.predict(tfidf_matrix_test)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(y_test, preds, color=colors[i], label=model_name)\n",
    "    plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'k--', lw=2)  \n",
    "    plt.xlabel('Actual Values')\n",
    "    plt.ylabel('Predicted Values')\n",
    "    plt.title(f'{model_name} Model Predictions vs Actual Values')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacking Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define base models based on the previous highest scores.\n",
    "\n",
    "base_models = [\n",
    "    ('linear', LinearRegression()),\n",
    "    ('Random Forest', RandomForestRegressor(n_estimators=100,random_state=42)),\n",
    "\n",
    "]\n",
    "\n",
    "# initialize the stacking regressor\n",
    "stacked_model = StackingRegressor(estimators=base_models, final_estimator=KNeighborsRegressor(n_neighbors=5))\n",
    "# train the stacking regressor\n",
    "stacked_model.fit(tfidf_matrix_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "preds = stacked_model.predict(tfidf_matrix_test)\n",
    "\n",
    "msle = mean_squared_log_error(y_test, preds)\n",
    "mae = mean_absolute_error(y_test, preds)  \n",
    "mse_regression = mean_squared_error(y_test, preds)  \n",
    "r2 = r2_score(y_test, preds)  \n",
    "score = 100 * max(0, 1 - msle)\n",
    "print(f\"| StackingRegressor | {score:10.2f} | {mae:10.2f} | {mse_regression:10.2f} | {r2:10.2f} |\")\n",
    "\n",
    "# plot the scatterplot for stacking emsemble\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, preds, color='red', label=model_name)\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'k--', lw=2)  \n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title(f'{model_name} Model Predictions vs Actual Values')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feed Forward Neural Network with TF-IDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traincsv = pd.read_csv('Dataset/train.csv')\n",
    "testcsv = pd.read_csv('Dataset/test(with_results).csv')\n",
    "\n",
    "y_train = traincsv['Match Percentage'].to_numpy()\n",
    "y_test = testcsv['Match Percentage'].to_numpy()\n",
    "# Convert sparse matrices to dense arrays\n",
    "X_train_dense = tfidf_matrix_train.toarray()\n",
    "X_test_dense = tfidf_matrix_test.toarray()\n",
    "# create input-output pair and batch the data.\n",
    "X_train_data = tf.data.Dataset \\\n",
    "                .from_tensor_slices((X_train_dense, y_train)) \\\n",
    "                .batch(4).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "X_test_data = tf.data.Dataset \\\n",
    "                .from_tensor_slices((X_test_dense, y_test)) \\\n",
    "                .batch(4).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "X_train_dense.shape\n",
    "X_test_dense.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create simple FFNN with TF2 functional API\n",
    "\n",
    "inp = layers.Input(shape=(1927,))\n",
    "x = layers.Dense(64, activation='relu')(inp)\n",
    "x = layers.Dense(8, activation='relu')(x)\n",
    "out = layers.Dense(1, activation='relu')(x)\n",
    "TFIDFmodel = tf.keras.Model(inputs=inp, outputs=out, name='TFIDF')\n",
    "tf.keras.utils.plot_model(TFIDFmodel, \"FFNN.png\", show_shapes=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# compile the model with adam optemizer\n",
    "TFIDFmodel.compile(optimizer=tf.keras.optimizers.Adam(\n",
    "        learning_rate=1e-6), loss='mse', metrics=['mae'])\n",
    "\n",
    "# train the model\n",
    "history = TFIDFmodel.fit(\n",
    "    X_train_data,\n",
    "    epochs=40000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show loss curve\n",
    "loss = history.history['loss']\n",
    "\n",
    "plt.plot(loss, label='Training MSE')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('MSE per Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model on the test data\n",
    "\n",
    "predictions = TFIDFmodel.predict(X_test_data)\n",
    "score  = 100* max(0,1-  mean_squared_log_error(y_test, predictions))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT with Feed Forward Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# Clear TensorFlow session\n",
    "K.clear_session()\n",
    "\n",
    "# load pretrained models\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "distilbert_model = TFDistilBertModel.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the job_description from the pdf \n",
    "job_description = extract_text_from_pdf(\"Dataset\\Job description.pdf\")\n",
    "# encode with the tokenizer\n",
    "job_description_encoded = tokenizer.encode(job_description, max_length=300, padding='max_length', truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traincsv = pd.read_csv('Dataset/train.csv')\n",
    "testcsv = pd.read_csv('Dataset/test(with_results).csv')\n",
    "\n",
    "# preprocess all resumes based on the BERT tokenizer and format\n",
    "\n",
    "train_resumes_encoded = []\n",
    "test_resumes_encoded = []\n",
    "for train_resume in train_resumes:\n",
    "    # encode with the tokenizer\n",
    "    resume_encoded = tokenizer.encode(train_resume, max_length=300, padding='max_length', truncation=True)\n",
    "    train_resumes_encoded.append(resume_encoded)\n",
    "resumes_encoded = np.array(train_resumes_encoded)\n",
    "\n",
    "for test_resume in test_resumes:\n",
    "    # encode with the tokenizer\n",
    "    test_resume_encoded = tokenizer.encode(test_resume, max_length=300, padding='max_length', truncation=True)\n",
    "    test_resumes_encoded.append(test_resume_encoded)\n",
    "test_resumes_encoded = np.array(test_resumes_encoded)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get output corresponding to CLS token\n",
    "job_description_cls = distilbert_model(np.array([job_description_encoded])).last_hidden_state[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_data = []\n",
    "for train_resume_encoded in train_resumes_encoded:\n",
    "    # get output corresponding to CLS token\n",
    "    train_resume_cls = distilbert_model(np.array([train_resume_encoded])).last_hidden_state[0][0]\n",
    "    X_train_data.append(tf.concat(axis=0, values = [job_description_cls, train_resume_cls]))\n",
    "X_train_data = np.array(X_train_data)\n",
    "X_train_data.shape\n",
    "\n",
    "X_test_data = []\n",
    "for test_resume_encoded in test_resumes_encoded:\n",
    "    # get output corresponding to CLS token\n",
    "    test_resume_cls = distilbert_model(np.array([test_resume_encoded])).last_hidden_state[0][0]\n",
    "    X_test_data.append(tf.concat(axis=0, values = [job_description_cls, test_resume_cls]))\n",
    "X_test_data = np.array(X_test_data)\n",
    "X_test_data.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the y values\n",
    "\n",
    "y_train = traincsv['Match Percentage'].to_numpy()\n",
    "y_test = testcsv['Match Percentage'].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create x y pair\n",
    "X_train_data_tf = tf.data.Dataset \\\n",
    "                .from_tensor_slices((X_train_data, y_train)) \\\n",
    "                .shuffle(100)\n",
    "\n",
    "\n",
    "X_test_data_tf = tf.data.Dataset \\\n",
    "                .from_tensor_slices((X_test_data, y_test)) \\\n",
    "                .shuffle(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "\n",
    "train_ds = X_train_data_tf.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "test_ds = X_test_data_tf.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a feed forward neuron network model for BERT outputs\n",
    "\n",
    "\n",
    "inp = tf.keras.layers.Input(shape=(1536,))\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(inp)\n",
    "x = tf.keras.layers.Dense(16, activation='relu')(x)\n",
    "out = tf.keras.layers.Dense(1, activation='relu')(x)\n",
    "\n",
    "BERTmodel = tf.keras.Model(inputs=inp, outputs=out, name='DistilBERT')\n",
    "BERTmodel.summary()\n",
    "tf.keras.utils.plot_model(BERTmodel, \"DistilBERT.png\", show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BERTmodel.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-6), loss='mse', metrics=['mae'])\n",
    "\n",
    "\n",
    "# train the model\n",
    "history = BERTmodel.fit(\n",
    "    train_ds,\n",
    "    epochs=20000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get the MAE and Loss from the history object\n",
    "mae = history.history['mae']\n",
    "loss = history.history['loss']\n",
    "epochs = range(1, len(mae) + 1)\n",
    "\n",
    "# plot the MAE\n",
    "plt.plot(epochs, mae, 'b', label='MAE')\n",
    "plt.title('Mean Absolute Error')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# plot the Loss\n",
    "plt.plot(epochs, loss, 'r', label='Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model on the test data\n",
    "test_loss, test_mae = BERTmodel.evaluate(test_ds)\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test MAE: {test_mae}\")\n",
    "\n",
    "predictions = BERTmodel.predict(X_test_data)\n",
    "score  = 100* max(0,1-  mean_squared_log_error(y_test, predictions))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
